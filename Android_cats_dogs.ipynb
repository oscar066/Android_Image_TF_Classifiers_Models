{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub \n",
    "import tensorflow_datasets as tfds\n",
    "import tf_keras as keras\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_RES = 224\n",
    "\n",
    "def format_image(image, label):\n",
    "    image = tf.image.resize(image, (IMAGE_RES, IMAGE_RES))/255.0\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23262\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-03 09:57:16.561894: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "(raw_train, raw_validation, raw_test) , metadata = tfds.load(\n",
    "    'cats_vs_dogs',\n",
    "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    ")\n",
    "\n",
    "num_examples = metadata.splits['train'].num_examples\n",
    "num_classes = metadata.features['label'].num_classes\n",
    "\n",
    "print(num_examples)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-03 09:57:20.457336: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:376] The default buffer size is 262144, which is overridden by the user specified `buffer_size` of 8388608\n",
      "2025-02-03 09:57:22.336394: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 224, 224, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_batches = raw_train.shuffle(num_examples // 4).map(format_image).batch(BATCH_SIZE)\n",
    "validation_batches = raw_validation.map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
    "test_batches = raw_test.map(format_image).batch(1)\n",
    "\n",
    "for  image_batch, label_batch in train_batches.take(1):\n",
    "    pass\n",
    "\n",
    "image_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_selection = (\"mobilenet_v2_100_224\", 224, 1280)\n",
    "handle_base, pixels, FV_SIZE = module_selection\n",
    "\n",
    "# Use the correct non-preview URL\n",
    "MODULE_HANDLE = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\".format(handle_base)\n",
    "\n",
    "IMAGE_SIZE = (pixels, pixels)\n",
    "\n",
    "feature_extractor = hub.KerasLayer(\n",
    "    MODULE_HANDLE,\n",
    "    input_shape=(224, 224, 3),\n",
    "    trainable=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 1280)              2257984   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 2562      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2260546 (8.62 MB)\n",
      "Trainable params: 2562 (10.01 KB)\n",
      "Non-trainable params: 2257984 (8.61 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    feature_extractor,\n",
    "    keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model \n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the log directory for TensorBoard\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Define the TensorBoard callback\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582/582 [==============================] - 136s 227ms/step - loss: 0.0535 - accuracy: 0.9808 - val_loss: 0.0406 - val_accuracy: 0.9854\n",
      "Epoch 2/5\n",
      "582/582 [==============================] - 133s 226ms/step - loss: 0.0298 - accuracy: 0.9895 - val_loss: 0.0357 - val_accuracy: 0.9880\n",
      "Epoch 3/5\n",
      "582/582 [==============================] - 133s 226ms/step - loss: 0.0254 - accuracy: 0.9910 - val_loss: 0.0452 - val_accuracy: 0.9845\n",
      "Epoch 4/5\n",
      "582/582 [==============================] - 140s 238ms/step - loss: 0.0216 - accuracy: 0.9923 - val_loss: 0.0386 - val_accuracy: 0.9875\n",
      "Epoch 5/5\n",
      "582/582 [==============================] - 139s 236ms/step - loss: 0.0185 - accuracy: 0.9939 - val_loss: 0.0434 - val_accuracy: 0.9867\n"
     ]
    }
   ],
   "source": [
    "# training the model \n",
    "hist = model.fit(\n",
    "    train_batches, \n",
    "    epochs=5,\n",
    "    validation_data=validation_batches,\n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-03 10:14:24.626409: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-03 10:14:24.638472: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738577664.652342   45421 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738577664.656182   45421 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-03 10:14:24.669348: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-03 10:14:26.866981: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.18.0 at http://localhost:6006/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2326/2326 [==============================] - 43s 18ms/step - loss: 0.0332 - accuracy: 0.9888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.033208198845386505, 0.9888219833374023]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluating the model\n",
    "model.evaluate(test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp_saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exp_saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "# saving the model\n",
    "CATS_VS_DOGS_SAVED_MODEL = \"exp_saved_model\"\n",
    "tf.saved_model.save(model, CATS_VS_DOGS_SAVED_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the Model to LiteRT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1738577943.958512   27531 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1738577943.958874   27531 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-02-03 10:19:03.959796: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: exp_saved_model\n",
      "2025-02-03 10:19:03.974557: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-02-03 10:19:03.974600: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: exp_saved_model\n",
      "I0000 00:00:1738577944.040027   27531 mlir_graph_optimization_pass.cc:401] MLIR V1 optimization pass is not enabled\n",
      "2025-02-03 10:19:04.052772: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-02-03 10:19:04.392584: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: exp_saved_model\n",
      "2025-02-03 10:19:04.529373: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 569586 microseconds.\n",
      "2025-02-03 10:19:04.749030: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(CATS_VS_DOGS_SAVED_MODEL)\n",
    "lite_model = converter.convert()\n",
    "lite_model_file = 'converted_model.tflite'\n",
    "\n",
    "with open(lite_model_file, 'wb') as f:\n",
    "    f.write(lite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
